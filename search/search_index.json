{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"START Project Documentation Hub \u00b6 Welcome to the comprehensive documentation for the START (Scalable, Tailored Active-inference Research & Training) project - an advanced AI-powered system for creating personalized Active Inference and Free Energy Principle curricula. \ud83d\ude80 What is START? \u00b6 START is a complete educational content generation pipeline that combines: Real-time research using Perplexity API for current domain insights Advanced LLM-based content generation via OpenRouter for professional-quality curricula Comprehensive personalization tailored to specific learners and professional domains Multilingual capabilities with full cultural adaptation Rich visualizations including charts, diagrams, and interactive elements \ud83d\udcda Documentation Structure \u00b6 graph TD A[\"START Docs Hub\"] --> B[\"Environment Setup\"] A --> C[\"Pipeline Overview\"] A --> D[\"Repository & Clone Management\"] A --> E[\"Testing Guide\"] A --> F[\"User & API Guides\"] F --> F1[\"Curriculum Creation Usage Guide\"] F --> F2[\"API Integration Guide\"] A --> I[\"Getting Started\"] A --> J[\"Configuration\"] A --> K[\"Examples\"] A --> L[\"Data & Outputs\"] A --> M[\"Visualizations\"] A --> N[\"Translations\"] A --> O[\"Docs & Deployment\"] A --> G[\"Configuration Reference\"] A --> H[\"Prompt Templates\"] click B \"./environment.md\" \"Environment Setup\" click C \"./pipeline.md\" \"Pipeline Overview\" click D \"./clones.md\" \"Repository & Clone Management\" click E \"./TESTING.md\" \"Testing Guide\" click F1 \"https://github.com/ActiveInferenceInstitute/Start/blob/main/learning/curriculum_creation/USAGE_GUIDE.md\" \"Usage Guide\" click F2 \"https://github.com/ActiveInferenceInstitute/Start/blob/main/learning/curriculum_creation/README.md\" \"API Integration Guide\" click I \"./getting_started.md\" \"Getting Started\" click J \"./configuration.md\" \"Configuration\" click K \"./examples.md\" \"Examples\" click L \"./data_outputs.md\" \"Data & Outputs\" click M \"./visualizations.md\" \"Visualizations\" click N \"./translations.md\" \"Translations\" click O \"./docs_and_deployment.md\" \"Docs & Deployment\" Core Guides \u00b6 \ud83d\udee0\ufe0f Setup & Development \u00b6 Environment Setup - Complete installation, configuration, and development guide Prerequisites, API setup, dependency management Development workflow, testing, troubleshooting IDE integration and advanced configuration \ud83d\udd04 System Architecture \u00b6 Pipeline Overview - Comprehensive system architecture and workflow 4-stage curriculum creation pipeline Configuration-driven research approach API integration and content generation standards \ud83d\udd17 External Integrations \u00b6 Repository & Clone Management - External resource integration Active Inference Institute ecosystem integration Knowledge graph and implementation repositories Educational resource enhancement strategies Specialized Documentation \u00b6 \ud83d\udcd6 User Guides \u00b6 Usage Guide API Integration Guide \ud83d\udd27 Configuration Reference \u00b6 Entity Configuration : data/config/entities.yaml - Target learner profiles Domain Configuration : data/config/domains.yaml - Professional domain definitions Language Configuration : data/config/languages.yaml - Translation targets \ud83d\udce6 Data & Outputs \u00b6 Data & Outputs - Where artifacts are written and how to use them \ud83d\udcca Visualizations \u00b6 Visualizations - Diagram and chart gallery with regeneration steps \ud83c\udf0d Translations \u00b6 Translations & Localization - Multilingual outputs and structure \ud83e\udded Docs & Deployment \u00b6 Docs & Deployment - Local serve, build, and GitHub Pages \ud83d\udcdd Prompt Engineering \u00b6 Domain Analysis Templates : data/prompts/research_domain_analysis.md Curriculum Generation Templates : data/prompts/research_domain_curriculum.md Personalization Templates : data/prompts/research_entity.md Translation Framework : data/prompts/translation.md \ud83c\udfaf Quick Start Paths \u00b6 For New Users \u00b6 Environment Setup - Get up and running Pipeline Overview - Understand the system Usage Guide (GitHub) For Developers \u00b6 Environment Setup - Development environment API Docs (GitHub) Tests (GitHub) For Researchers \u00b6 Pipeline Overview - Research capabilities Clone Management - Access research repositories Configuration Files - Customize research targets \ud83c\udf10 External Resources \u00b6 Active Inference Institute Ecosystem \u00b6 Website : activeinference.institute Activities : activities.activeinference.institute X (Twitter) : x.com/InferenceActive Discord : discord.activeinference.institute Donate : donate.activeinference.institute YouTube : youtube.com/c/ActiveInference Livestreams : video.activeinference.institute Math & Programming Resources \u00b6 pymdp (official) : infer-actively/pymdp Active Inference Tutorial Scripts : rssmith33/Active-Inference-Tutorial-Scripts Free Energy Principle papers : activeinference.github.io Active Inference: Demystified and Compared : arXiv:1909.10863 Step-by-Step Tutorial : PMC In-Repo Entry Points \u00b6 Top-level landing page : Here \u2014 starting at start/here Other materials : docs/other/inferant_stream_015-1.md \ud83d\udccb System Capabilities \u00b6 Research & Analysis \u00b6 ** Professional Domains**: Life sciences, technology, business, healthcare, education, and whatever you prefer. 8 Target Entities : Political figures, scientists, tech leaders, educators, any entity or audience you prefer Real-time Research : Current industry insights and professional analysis Comprehensive Analysis : 3,000-5,000 word domain reports Content Generation \u00b6 Professional-Grade Curricula : 40-60 hour structured learning programs, eventually with more granular and custom productions possible in this repo Personalized Learning : 5,000-8,000 word tailored strategies Modular Design : 3-5 hour comprehensive learning units Assessment Integration : Built-in evaluation and progress tracking Visualization & Media \u00b6 Data Visualizations : PNG charts with curriculum metrics and analysis Process Diagrams : Mermaid diagrams for structure and flow Interactive Elements : Visual learning aids and conceptual frameworks Multilingual Support \u00b6 9+ Languages : Chinese, Spanish, Arabic, Hindi, French, Japanese, Russian, Swahili, Tagalog Cultural Adaptation : Full localization beyond literal translation Professional Quality : Native-speaker level fluency with technical accuracy \ud83d\udd27 Configuration Overview \u00b6 Research Configuration \u00b6 # data/config/entities.yaml entities: - name: \"karl_friston\" category: \"scientist\" priority: \"high\" # data/config/domains.yaml domains: - name: \"biochemistry\" category: \"life_sciences\" priority: \"high\" Command-Line Interface \u00b6 # Research high-priority entities python 1_Research_Entity.py --priority high # Generate domain-specific curricula python 1_Research_Domain.py --domain biochemistry # Create multilingual content python 4_Translate_Introductions.py --languages Spanish French \ud83d\udcca Project Structure \u00b6 START/ \u251c\u2500\u2500 src/ # Core system implementation \u251c\u2500\u2500 learning/ # Curriculum creation scripts \u251c\u2500\u2500 data/ # Generated content and configuration \u251c\u2500\u2500 docs/ # Comprehensive documentation \u251c\u2500\u2500 tests/ # Test suite and validation \u2514\u2500\u2500 README.md # Project overview and quick start \ud83d\udd04 Development Workflow \u00b6 Standard Development Cycle \u00b6 Configure targets in data/config/ YAML files Run research using domain and entity scripts Generate curricula with comprehensive content creation Create visualizations for enhanced learning Translate content for multilingual accessibility Quality Assurance \u00b6 Comprehensive testing with pytest and TDD approach Code quality with ruff linting and black formatting API integration testing for Perplexity and OpenRouter Content validation against Active Inference standards \ud83d\udcde Getting Help \u00b6 Documentation Resources \u00b6 This documentation hub for comprehensive guides Inline code documentation with detailed docstrings Example usage in test files and usage guides Configuration examples in YAML files Community & Support \u00b6 Active Inference Institute for research questions GitHub Issues for technical problems and feature requests Test Suite for usage examples and validation patterns START represents a new paradigm in educational content creation, combining cutting-edge AI research capabilities with comprehensive pedagogical design to produce world-class Active Inference curricula tailored to any professional domain or individual learner. Institute Shortlinks (email-friendly) \u00b6 2025: 2025.activeinference.institute Active Blockference: active-blockference.activeinference.institute Activities: activities.activeinference.institute Affordances: affordances.activeinference.institute Board of Directors (BoD): bod.activeinference.institute Discord: discord.activeinference.institute Donate: donate.activeinference.institute Ecosystem: ecosystem.activeinference.institute EduActive: eduactive.activeinference.institute Fellows: fellows.activeinference.institute Fellowship: fellowship.activeinference.institute Internships: intern.activeinference.institute Knowledge Engineering: knowledge-engineering.activeinference.institute Measure: measure.activeinference.institute Mentorship: mentorship.activeinference.institute Newsletter: newsletter.activeinference.institute Obsidian (Knowledge Graph): obsidian.activeinference.institute Ontology: ontology.activeinference.institute Partnership: partnership.activeinference.institute Partnerships: partnerships.activeinference.institute PayPal: paypal.activeinference.institute Prepare: prepare.activeinference.institute Projects: projects.activeinference.institute ReInference: reinference.activeinference.institute RxInfer: rxinfer.activeinference.institute SAB: sab.activeinference.institute Strategy: strategy.activeinference.institute Support: support.activeinference.institute Symposium: symposium.activeinference.institute Textbook Group: textbook-group.activeinference.institute TNB: tnb.activeinference.institute Video: video.activeinference.institute Volunteer: volunteer.activeinference.institute Wave Hypothesis: wave-hypothesis.activeinference.institute Weekly: weekly.activeinference.institute Welcome: welcome.activeinference.institute","title":"Home"},{"location":"#start-project-documentation-hub","text":"Welcome to the comprehensive documentation for the START (Scalable, Tailored Active-inference Research & Training) project - an advanced AI-powered system for creating personalized Active Inference and Free Energy Principle curricula.","title":"START Project Documentation Hub"},{"location":"#what-is-start","text":"START is a complete educational content generation pipeline that combines: Real-time research using Perplexity API for current domain insights Advanced LLM-based content generation via OpenRouter for professional-quality curricula Comprehensive personalization tailored to specific learners and professional domains Multilingual capabilities with full cultural adaptation Rich visualizations including charts, diagrams, and interactive elements","title":"\ud83d\ude80 What is START?"},{"location":"#documentation-structure","text":"graph TD A[\"START Docs Hub\"] --> B[\"Environment Setup\"] A --> C[\"Pipeline Overview\"] A --> D[\"Repository & Clone Management\"] A --> E[\"Testing Guide\"] A --> F[\"User & API Guides\"] F --> F1[\"Curriculum Creation Usage Guide\"] F --> F2[\"API Integration Guide\"] A --> I[\"Getting Started\"] A --> J[\"Configuration\"] A --> K[\"Examples\"] A --> L[\"Data & Outputs\"] A --> M[\"Visualizations\"] A --> N[\"Translations\"] A --> O[\"Docs & Deployment\"] A --> G[\"Configuration Reference\"] A --> H[\"Prompt Templates\"] click B \"./environment.md\" \"Environment Setup\" click C \"./pipeline.md\" \"Pipeline Overview\" click D \"./clones.md\" \"Repository & Clone Management\" click E \"./TESTING.md\" \"Testing Guide\" click F1 \"https://github.com/ActiveInferenceInstitute/Start/blob/main/learning/curriculum_creation/USAGE_GUIDE.md\" \"Usage Guide\" click F2 \"https://github.com/ActiveInferenceInstitute/Start/blob/main/learning/curriculum_creation/README.md\" \"API Integration Guide\" click I \"./getting_started.md\" \"Getting Started\" click J \"./configuration.md\" \"Configuration\" click K \"./examples.md\" \"Examples\" click L \"./data_outputs.md\" \"Data & Outputs\" click M \"./visualizations.md\" \"Visualizations\" click N \"./translations.md\" \"Translations\" click O \"./docs_and_deployment.md\" \"Docs & Deployment\"","title":"\ud83d\udcda Documentation Structure"},{"location":"#core-guides","text":"","title":"Core Guides"},{"location":"#setup-development","text":"Environment Setup - Complete installation, configuration, and development guide Prerequisites, API setup, dependency management Development workflow, testing, troubleshooting IDE integration and advanced configuration","title":"\ud83d\udee0\ufe0f Setup &amp; Development"},{"location":"#system-architecture","text":"Pipeline Overview - Comprehensive system architecture and workflow 4-stage curriculum creation pipeline Configuration-driven research approach API integration and content generation standards","title":"\ud83d\udd04 System Architecture"},{"location":"#external-integrations","text":"Repository & Clone Management - External resource integration Active Inference Institute ecosystem integration Knowledge graph and implementation repositories Educational resource enhancement strategies","title":"\ud83d\udd17 External Integrations"},{"location":"#specialized-documentation","text":"","title":"Specialized Documentation"},{"location":"#user-guides","text":"Usage Guide API Integration Guide","title":"\ud83d\udcd6 User Guides"},{"location":"#configuration-reference","text":"Entity Configuration : data/config/entities.yaml - Target learner profiles Domain Configuration : data/config/domains.yaml - Professional domain definitions Language Configuration : data/config/languages.yaml - Translation targets","title":"\ud83d\udd27 Configuration Reference"},{"location":"#data-outputs","text":"Data & Outputs - Where artifacts are written and how to use them","title":"\ud83d\udce6 Data &amp; Outputs"},{"location":"#visualizations","text":"Visualizations - Diagram and chart gallery with regeneration steps","title":"\ud83d\udcca Visualizations"},{"location":"#translations","text":"Translations & Localization - Multilingual outputs and structure","title":"\ud83c\udf0d Translations"},{"location":"#docs-deployment","text":"Docs & Deployment - Local serve, build, and GitHub Pages","title":"\ud83e\udded Docs &amp; Deployment"},{"location":"#prompt-engineering","text":"Domain Analysis Templates : data/prompts/research_domain_analysis.md Curriculum Generation Templates : data/prompts/research_domain_curriculum.md Personalization Templates : data/prompts/research_entity.md Translation Framework : data/prompts/translation.md","title":"\ud83d\udcdd Prompt Engineering"},{"location":"#quick-start-paths","text":"","title":"\ud83c\udfaf Quick Start Paths"},{"location":"#for-new-users","text":"Environment Setup - Get up and running Pipeline Overview - Understand the system Usage Guide (GitHub)","title":"For New Users"},{"location":"#for-developers","text":"Environment Setup - Development environment API Docs (GitHub) Tests (GitHub)","title":"For Developers"},{"location":"#for-researchers","text":"Pipeline Overview - Research capabilities Clone Management - Access research repositories Configuration Files - Customize research targets","title":"For Researchers"},{"location":"#external-resources","text":"","title":"\ud83c\udf10 External Resources"},{"location":"#active-inference-institute-ecosystem","text":"Website : activeinference.institute Activities : activities.activeinference.institute X (Twitter) : x.com/InferenceActive Discord : discord.activeinference.institute Donate : donate.activeinference.institute YouTube : youtube.com/c/ActiveInference Livestreams : video.activeinference.institute","title":"Active Inference Institute Ecosystem"},{"location":"#math-programming-resources","text":"pymdp (official) : infer-actively/pymdp Active Inference Tutorial Scripts : rssmith33/Active-Inference-Tutorial-Scripts Free Energy Principle papers : activeinference.github.io Active Inference: Demystified and Compared : arXiv:1909.10863 Step-by-Step Tutorial : PMC","title":"Math &amp; Programming Resources"},{"location":"#in-repo-entry-points","text":"Top-level landing page : Here \u2014 starting at start/here Other materials : docs/other/inferant_stream_015-1.md","title":"In-Repo Entry Points"},{"location":"#system-capabilities","text":"","title":"\ud83d\udccb System Capabilities"},{"location":"#research-analysis","text":"** Professional Domains**: Life sciences, technology, business, healthcare, education, and whatever you prefer. 8 Target Entities : Political figures, scientists, tech leaders, educators, any entity or audience you prefer Real-time Research : Current industry insights and professional analysis Comprehensive Analysis : 3,000-5,000 word domain reports","title":"Research &amp; Analysis"},{"location":"#content-generation","text":"Professional-Grade Curricula : 40-60 hour structured learning programs, eventually with more granular and custom productions possible in this repo Personalized Learning : 5,000-8,000 word tailored strategies Modular Design : 3-5 hour comprehensive learning units Assessment Integration : Built-in evaluation and progress tracking","title":"Content Generation"},{"location":"#visualization-media","text":"Data Visualizations : PNG charts with curriculum metrics and analysis Process Diagrams : Mermaid diagrams for structure and flow Interactive Elements : Visual learning aids and conceptual frameworks","title":"Visualization &amp; Media"},{"location":"#multilingual-support","text":"9+ Languages : Chinese, Spanish, Arabic, Hindi, French, Japanese, Russian, Swahili, Tagalog Cultural Adaptation : Full localization beyond literal translation Professional Quality : Native-speaker level fluency with technical accuracy","title":"Multilingual Support"},{"location":"#configuration-overview","text":"","title":"\ud83d\udd27 Configuration Overview"},{"location":"#research-configuration","text":"# data/config/entities.yaml entities: - name: \"karl_friston\" category: \"scientist\" priority: \"high\" # data/config/domains.yaml domains: - name: \"biochemistry\" category: \"life_sciences\" priority: \"high\"","title":"Research Configuration"},{"location":"#command-line-interface","text":"# Research high-priority entities python 1_Research_Entity.py --priority high # Generate domain-specific curricula python 1_Research_Domain.py --domain biochemistry # Create multilingual content python 4_Translate_Introductions.py --languages Spanish French","title":"Command-Line Interface"},{"location":"#project-structure","text":"START/ \u251c\u2500\u2500 src/ # Core system implementation \u251c\u2500\u2500 learning/ # Curriculum creation scripts \u251c\u2500\u2500 data/ # Generated content and configuration \u251c\u2500\u2500 docs/ # Comprehensive documentation \u251c\u2500\u2500 tests/ # Test suite and validation \u2514\u2500\u2500 README.md # Project overview and quick start","title":"\ud83d\udcca Project Structure"},{"location":"#development-workflow","text":"","title":"\ud83d\udd04 Development Workflow"},{"location":"#standard-development-cycle","text":"Configure targets in data/config/ YAML files Run research using domain and entity scripts Generate curricula with comprehensive content creation Create visualizations for enhanced learning Translate content for multilingual accessibility","title":"Standard Development Cycle"},{"location":"#quality-assurance","text":"Comprehensive testing with pytest and TDD approach Code quality with ruff linting and black formatting API integration testing for Perplexity and OpenRouter Content validation against Active Inference standards","title":"Quality Assurance"},{"location":"#getting-help","text":"","title":"\ud83d\udcde Getting Help"},{"location":"#documentation-resources","text":"This documentation hub for comprehensive guides Inline code documentation with detailed docstrings Example usage in test files and usage guides Configuration examples in YAML files","title":"Documentation Resources"},{"location":"#community-support","text":"Active Inference Institute for research questions GitHub Issues for technical problems and feature requests Test Suite for usage examples and validation patterns START represents a new paradigm in educational content creation, combining cutting-edge AI research capabilities with comprehensive pedagogical design to produce world-class Active Inference curricula tailored to any professional domain or individual learner.","title":"Community &amp; Support"},{"location":"#institute-shortlinks-email-friendly","text":"2025: 2025.activeinference.institute Active Blockference: active-blockference.activeinference.institute Activities: activities.activeinference.institute Affordances: affordances.activeinference.institute Board of Directors (BoD): bod.activeinference.institute Discord: discord.activeinference.institute Donate: donate.activeinference.institute Ecosystem: ecosystem.activeinference.institute EduActive: eduactive.activeinference.institute Fellows: fellows.activeinference.institute Fellowship: fellowship.activeinference.institute Internships: intern.activeinference.institute Knowledge Engineering: knowledge-engineering.activeinference.institute Measure: measure.activeinference.institute Mentorship: mentorship.activeinference.institute Newsletter: newsletter.activeinference.institute Obsidian (Knowledge Graph): obsidian.activeinference.institute Ontology: ontology.activeinference.institute Partnership: partnership.activeinference.institute Partnerships: partnerships.activeinference.institute PayPal: paypal.activeinference.institute Prepare: prepare.activeinference.institute Projects: projects.activeinference.institute ReInference: reinference.activeinference.institute RxInfer: rxinfer.activeinference.institute SAB: sab.activeinference.institute Strategy: strategy.activeinference.institute Support: support.activeinference.institute Symposium: symposium.activeinference.institute Textbook Group: textbook-group.activeinference.institute TNB: tnb.activeinference.institute Video: video.activeinference.institute Volunteer: volunteer.activeinference.institute Wave Hypothesis: wave-hypothesis.activeinference.institute Weekly: weekly.activeinference.institute Welcome: welcome.activeinference.institute","title":"Institute Shortlinks (email-friendly)"},{"location":"TESTING/","text":"Testing Guide \u00b6 This document defines the testing policy and workflows for the START project. Core Principles \u00b6 Real I/O, no stubs or fakes in tests No network by default; allow network only if CI=true Deterministic, portable, and fast sequenceDiagram participant Dev as Developer participant Py as pytest participant Off as Offline tests participant Net as Network tests Dev->>Py: uv run pytest -q Py->>Off: Run (always) alt CI=true and network enabled Py->>Net: Run @network tests else Py-->>Dev: Skip @network tests end Test Structure \u00b6 Unit Tests \u00b6 Common utilities: test_common_*.py Core modules: test_domain.py , test_entity.py Configuration: test_config.py , test_languages_config.py System components: test_system_*.py Script & Integration Tests \u00b6 Research scripts: test_1_research_domain.py , test_2_write_introduction.py Visualization scripts: test_3_introduction_visualizations.py Translation scripts: test_4_translate_introductions.py End-to-end: test_integration.py Repo management: test_repos_*.py Running Tests \u00b6 # Full suite uv run pytest -q # Verbose / coverage uv run pytest -v uv run pytest --cov=src --cov-report=html # Focused runs uv run pytest -k \"domain\" uv run pytest tests/test_domain.py Markers \u00b6 @pytest.mark.integration : end-to-end or cross-module behavior @pytest.mark.slow : long-running @pytest.mark.network : requires external network/APIs Gate network tests behind CI: import os import pytest RUN_NETWORK = os.getenv(\"CI\") == \"true\" network = pytest.mark.network def skip_network_if_disallowed(): if not RUN_NETWORK: pytest.skip(\"Network tests disabled outside CI\") @network def test_network_feature(): skip_network_if_disallowed() # real network call here Offline-First Testing \u00b6 Use real files and fixtures; avoid mocks Prefer tmp_path for writable temp dirs Store canonical inputs/outputs under data/Languages/Inputs_and_Outputs/** as allowed by policy def test_file_processing(tmp_path): source = tmp_path / \"input.json\" source.write_text('{\"a\": 1}') result = process_file(source) assert result[\"a\"] == 1 Environment Setup for Tests \u00b6 # Non-GUI matplotlib backend export MPLBACKEND=Agg # Optional: keys for CI network tests export PERPLEXITY_API_KEY=\"...\" export OPENROUTER_API_KEY=\"...\" Coverage \u00b6 uv run pytest --cov=src --cov-report=html Best Practices \u00b6 Isolate tests; keep them small and readable Assert on behavior and artifacts (files, return values) Keep runtime low; mark slow cases with @pytest.mark.slow Avoid brittle coupling to implementation details","title":"Testing"},{"location":"TESTING/#testing-guide","text":"This document defines the testing policy and workflows for the START project.","title":"Testing Guide"},{"location":"TESTING/#core-principles","text":"Real I/O, no stubs or fakes in tests No network by default; allow network only if CI=true Deterministic, portable, and fast sequenceDiagram participant Dev as Developer participant Py as pytest participant Off as Offline tests participant Net as Network tests Dev->>Py: uv run pytest -q Py->>Off: Run (always) alt CI=true and network enabled Py->>Net: Run @network tests else Py-->>Dev: Skip @network tests end","title":"Core Principles"},{"location":"TESTING/#test-structure","text":"","title":"Test Structure"},{"location":"TESTING/#unit-tests","text":"Common utilities: test_common_*.py Core modules: test_domain.py , test_entity.py Configuration: test_config.py , test_languages_config.py System components: test_system_*.py","title":"Unit Tests"},{"location":"TESTING/#script-integration-tests","text":"Research scripts: test_1_research_domain.py , test_2_write_introduction.py Visualization scripts: test_3_introduction_visualizations.py Translation scripts: test_4_translate_introductions.py End-to-end: test_integration.py Repo management: test_repos_*.py","title":"Script &amp; Integration Tests"},{"location":"TESTING/#running-tests","text":"# Full suite uv run pytest -q # Verbose / coverage uv run pytest -v uv run pytest --cov=src --cov-report=html # Focused runs uv run pytest -k \"domain\" uv run pytest tests/test_domain.py","title":"Running Tests"},{"location":"TESTING/#markers","text":"@pytest.mark.integration : end-to-end or cross-module behavior @pytest.mark.slow : long-running @pytest.mark.network : requires external network/APIs Gate network tests behind CI: import os import pytest RUN_NETWORK = os.getenv(\"CI\") == \"true\" network = pytest.mark.network def skip_network_if_disallowed(): if not RUN_NETWORK: pytest.skip(\"Network tests disabled outside CI\") @network def test_network_feature(): skip_network_if_disallowed() # real network call here","title":"Markers"},{"location":"TESTING/#offline-first-testing","text":"Use real files and fixtures; avoid mocks Prefer tmp_path for writable temp dirs Store canonical inputs/outputs under data/Languages/Inputs_and_Outputs/** as allowed by policy def test_file_processing(tmp_path): source = tmp_path / \"input.json\" source.write_text('{\"a\": 1}') result = process_file(source) assert result[\"a\"] == 1","title":"Offline-First Testing"},{"location":"TESTING/#environment-setup-for-tests","text":"# Non-GUI matplotlib backend export MPLBACKEND=Agg # Optional: keys for CI network tests export PERPLEXITY_API_KEY=\"...\" export OPENROUTER_API_KEY=\"...\"","title":"Environment Setup for Tests"},{"location":"TESTING/#coverage","text":"uv run pytest --cov=src --cov-report=html","title":"Coverage"},{"location":"TESTING/#best-practices","text":"Isolate tests; keep them small and readable Assert on behavior and artifacts (files, return values) Keep runtime low; mark slow cases with @pytest.mark.slow Avoid brittle coupling to implementation details","title":"Best Practices"},{"location":"clones/","text":"External Repositories & Clone Management \u00b6 The START project integrates with several Active Inference and computational neuroscience repositories to provide comprehensive educational resources and examples. These can be optionally cloned into src/_clones/ for local development and curriculum enhancement. Repository Ecosystem \u00b6 Core Knowledge Resources \u00b6 cognitive (Active Inference Institute Knowledge Graph) \u00b6 URL : github.com/ActiveInferenceInstitute/cognitive Destination : src/_clones/cognitive Purpose : Knowledge graph backing for curriculum development, providing structured Active Inference concepts and relationships Integration : Used as reference material for comprehensive curriculum content and concept validation RxInferExamples.jl (Bayesian Inference Examples) \u00b6 URL : github.com/docxology/RxInferExamples.jl Destination : src/_clones/RxInferExamples.jl Purpose : Practical examples of Bayesian inference and probabilistic programming Integration : Source of hands-on exercises and computational examples for technical curricula Implementation Resources \u00b6 ActiveInference.jl (Julia Implementation) \u00b6 URL : github.com/docxology/ActiveInference.jl/tree/textbook Destination : src/_clones/ActiveInference.jl Branch : textbook (educational focus) Purpose : Julia-based Active Inference implementation with educational documentation Integration : Technical reference and code examples for programming-focused curricula pymdp (Python Active Inference) \u00b6 URL : github.com/docxology/pymdp/tree/textbook Destination : src/_clones/pymdp Branch : textbook (educational focus) Purpose : Python implementation of Active Inference and Free Energy Principle Integration : Hands-on programming exercises and computational examples Clone Management \u00b6 flowchart LR A[Select repo] --> B{Already cloned?} B -- No --> C[Run clone utility] B -- Yes --> D[Update via git pull] C --> E[Verify destination non-empty] E --> F[Integration checks] D --> F[Integration checks] F --> G{Use in pipeline?} G -- cognitive --> H[Concept validation] G -- pymdp/ActiveInference.jl --> I[Examples & labs] G -- RxInferExamples.jl --> J[Exercises] click C \"../src/repos/clone_repo.py\" \"Clone utility\" Automated Cloning \u00b6 Use the integrated clone utility for consistent repository management: # Core knowledge graph uv run python src/repos/clone_repo.py --url https://github.com/ActiveInferenceInstitute/cognitive --dest src/_clones/cognitive --shallow # Bayesian inference examples uv run python src/repos/clone_repo.py --url https://github.com/docxology/RxInferExamples.jl --dest src/_clones/RxInferExamples.jl --shallow # Julia Active Inference (textbook branch) uv run python src/repos/clone_repo.py --url https://github.com/docxology/ActiveInference.jl --dest src/_clones/ActiveInference.jl --branch textbook --shallow # Python Active Inference (textbook branch) uv run python src/repos/clone_repo.py --url https://github.com/docxology/pymdp --dest src/_clones/pymdp --branch textbook --shallow Manual Repository Management \u00b6 # Clone with specific options git clone --shallow-since=\"2023-01-01\" --branch textbook https://github.com/docxology/ActiveInference.jl src/_clones/ActiveInference.jl # Update existing clones cd src/_clones/cognitive && git pull origin main cd src/_clones/pymdp && git pull origin textbook Integration with Curriculum Pipeline \u00b6 Knowledge Graph Integration \u00b6 cognitive repository provides structured concept relationships Used by domain analysis scripts to validate Active Inference concepts Enhances curriculum content with authoritative concept definitions Code Example Integration \u00b6 pymdp and ActiveInference.jl provide working code examples Integrated into hands-on curriculum sections Used for generating programming exercises and computational labs Educational Resource Enhancement \u00b6 RxInferExamples.jl provides practical Bayesian inference examples Textbook branches focus on educational content and clear explanations Examples adapted for domain-specific curriculum applications Repository Structure After Cloning \u00b6 src/_clones/ \u251c\u2500\u2500 cognitive/ # Knowledge graph and concept definitions \u2502 \u251c\u2500\u2500 content/ # Structured Active Inference content \u2502 \u2514\u2500\u2500 ontologies/ # Formal concept relationships \u251c\u2500\u2500 RxInferExamples.jl/ # Bayesian inference examples \u2502 \u251c\u2500\u2500 notebooks/ # Jupyter notebooks with examples \u2502 \u2514\u2500\u2500 scripts/ # Standalone example scripts \u251c\u2500\u2500 ActiveInference.jl/ # Julia Active Inference implementation \u2502 \u251c\u2500\u2500 docs/ # Educational documentation \u2502 \u251c\u2500\u2500 examples/ # Code examples and tutorials \u2502 \u2514\u2500\u2500 src/ # Core implementation \u2514\u2500\u2500 pymdp/ # Python Active Inference \u251c\u2500\u2500 notebooks/ # Educational notebooks \u251c\u2500\u2500 examples/ # Example scripts and demonstrations \u2514\u2500\u2500 pymdp/ # Core Python package Usage in Curriculum Development \u00b6 Content Enhancement \u00b6 Reference cloned repositories for authoritative Active Inference content Adapt examples from implementation repositories for specific domains Use knowledge graph structure to ensure comprehensive concept coverage Technical Integration \u00b6 Import code examples into curriculum programming sections Generate domain-specific computational exercises Provide working implementations for hands-on learning Quality Assurance \u00b6 Validate curriculum content against authoritative sources Ensure technical accuracy using reference implementations Maintain consistency with Active Inference Institute standards Verification & Maintenance \u00b6 Verify Clone Integrity \u00b6 # Path exists and is a git repo test -d src/_clones/cognitive/.git && echo OK # Show remote and branch git -C src/_clones/cognitive remote -v git -C src/_clones/cognitive branch --show-current Update Clones Safely \u00b6 git -C src/_clones/cognitive fetch --prune git -C src/_clones/cognitive pull --ff-only origin main git -C src/_clones/pymdp fetch --prune git -C src/_clones/pymdp pull --ff-only origin textbook Re-clone When Needed \u00b6 rm -rf src/_clones/ActiveInference.jl uv run python src/repos/clone_repo.py --url https://github.com/docxology/ActiveInference.jl --dest src/_clones/ActiveInference.jl --branch textbook --shallow","title":"Clone Management"},{"location":"clones/#external-repositories-clone-management","text":"The START project integrates with several Active Inference and computational neuroscience repositories to provide comprehensive educational resources and examples. These can be optionally cloned into src/_clones/ for local development and curriculum enhancement.","title":"External Repositories &amp; Clone Management"},{"location":"clones/#repository-ecosystem","text":"","title":"Repository Ecosystem"},{"location":"clones/#core-knowledge-resources","text":"","title":"Core Knowledge Resources"},{"location":"clones/#cognitive-active-inference-institute-knowledge-graph","text":"URL : github.com/ActiveInferenceInstitute/cognitive Destination : src/_clones/cognitive Purpose : Knowledge graph backing for curriculum development, providing structured Active Inference concepts and relationships Integration : Used as reference material for comprehensive curriculum content and concept validation","title":"cognitive (Active Inference Institute Knowledge Graph)"},{"location":"clones/#rxinferexamplesjl-bayesian-inference-examples","text":"URL : github.com/docxology/RxInferExamples.jl Destination : src/_clones/RxInferExamples.jl Purpose : Practical examples of Bayesian inference and probabilistic programming Integration : Source of hands-on exercises and computational examples for technical curricula","title":"RxInferExamples.jl (Bayesian Inference Examples)"},{"location":"clones/#implementation-resources","text":"","title":"Implementation Resources"},{"location":"clones/#activeinferencejl-julia-implementation","text":"URL : github.com/docxology/ActiveInference.jl/tree/textbook Destination : src/_clones/ActiveInference.jl Branch : textbook (educational focus) Purpose : Julia-based Active Inference implementation with educational documentation Integration : Technical reference and code examples for programming-focused curricula","title":"ActiveInference.jl (Julia Implementation)"},{"location":"clones/#pymdp-python-active-inference","text":"URL : github.com/docxology/pymdp/tree/textbook Destination : src/_clones/pymdp Branch : textbook (educational focus) Purpose : Python implementation of Active Inference and Free Energy Principle Integration : Hands-on programming exercises and computational examples","title":"pymdp (Python Active Inference)"},{"location":"clones/#clone-management","text":"flowchart LR A[Select repo] --> B{Already cloned?} B -- No --> C[Run clone utility] B -- Yes --> D[Update via git pull] C --> E[Verify destination non-empty] E --> F[Integration checks] D --> F[Integration checks] F --> G{Use in pipeline?} G -- cognitive --> H[Concept validation] G -- pymdp/ActiveInference.jl --> I[Examples & labs] G -- RxInferExamples.jl --> J[Exercises] click C \"../src/repos/clone_repo.py\" \"Clone utility\"","title":"Clone Management"},{"location":"clones/#automated-cloning","text":"Use the integrated clone utility for consistent repository management: # Core knowledge graph uv run python src/repos/clone_repo.py --url https://github.com/ActiveInferenceInstitute/cognitive --dest src/_clones/cognitive --shallow # Bayesian inference examples uv run python src/repos/clone_repo.py --url https://github.com/docxology/RxInferExamples.jl --dest src/_clones/RxInferExamples.jl --shallow # Julia Active Inference (textbook branch) uv run python src/repos/clone_repo.py --url https://github.com/docxology/ActiveInference.jl --dest src/_clones/ActiveInference.jl --branch textbook --shallow # Python Active Inference (textbook branch) uv run python src/repos/clone_repo.py --url https://github.com/docxology/pymdp --dest src/_clones/pymdp --branch textbook --shallow","title":"Automated Cloning"},{"location":"clones/#manual-repository-management","text":"# Clone with specific options git clone --shallow-since=\"2023-01-01\" --branch textbook https://github.com/docxology/ActiveInference.jl src/_clones/ActiveInference.jl # Update existing clones cd src/_clones/cognitive && git pull origin main cd src/_clones/pymdp && git pull origin textbook","title":"Manual Repository Management"},{"location":"clones/#integration-with-curriculum-pipeline","text":"","title":"Integration with Curriculum Pipeline"},{"location":"clones/#knowledge-graph-integration","text":"cognitive repository provides structured concept relationships Used by domain analysis scripts to validate Active Inference concepts Enhances curriculum content with authoritative concept definitions","title":"Knowledge Graph Integration"},{"location":"clones/#code-example-integration","text":"pymdp and ActiveInference.jl provide working code examples Integrated into hands-on curriculum sections Used for generating programming exercises and computational labs","title":"Code Example Integration"},{"location":"clones/#educational-resource-enhancement","text":"RxInferExamples.jl provides practical Bayesian inference examples Textbook branches focus on educational content and clear explanations Examples adapted for domain-specific curriculum applications","title":"Educational Resource Enhancement"},{"location":"clones/#repository-structure-after-cloning","text":"src/_clones/ \u251c\u2500\u2500 cognitive/ # Knowledge graph and concept definitions \u2502 \u251c\u2500\u2500 content/ # Structured Active Inference content \u2502 \u2514\u2500\u2500 ontologies/ # Formal concept relationships \u251c\u2500\u2500 RxInferExamples.jl/ # Bayesian inference examples \u2502 \u251c\u2500\u2500 notebooks/ # Jupyter notebooks with examples \u2502 \u2514\u2500\u2500 scripts/ # Standalone example scripts \u251c\u2500\u2500 ActiveInference.jl/ # Julia Active Inference implementation \u2502 \u251c\u2500\u2500 docs/ # Educational documentation \u2502 \u251c\u2500\u2500 examples/ # Code examples and tutorials \u2502 \u2514\u2500\u2500 src/ # Core implementation \u2514\u2500\u2500 pymdp/ # Python Active Inference \u251c\u2500\u2500 notebooks/ # Educational notebooks \u251c\u2500\u2500 examples/ # Example scripts and demonstrations \u2514\u2500\u2500 pymdp/ # Core Python package","title":"Repository Structure After Cloning"},{"location":"clones/#usage-in-curriculum-development","text":"","title":"Usage in Curriculum Development"},{"location":"clones/#content-enhancement","text":"Reference cloned repositories for authoritative Active Inference content Adapt examples from implementation repositories for specific domains Use knowledge graph structure to ensure comprehensive concept coverage","title":"Content Enhancement"},{"location":"clones/#technical-integration","text":"Import code examples into curriculum programming sections Generate domain-specific computational exercises Provide working implementations for hands-on learning","title":"Technical Integration"},{"location":"clones/#quality-assurance","text":"Validate curriculum content against authoritative sources Ensure technical accuracy using reference implementations Maintain consistency with Active Inference Institute standards","title":"Quality Assurance"},{"location":"clones/#verification-maintenance","text":"","title":"Verification &amp; Maintenance"},{"location":"clones/#verify-clone-integrity","text":"# Path exists and is a git repo test -d src/_clones/cognitive/.git && echo OK # Show remote and branch git -C src/_clones/cognitive remote -v git -C src/_clones/cognitive branch --show-current","title":"Verify Clone Integrity"},{"location":"clones/#update-clones-safely","text":"git -C src/_clones/cognitive fetch --prune git -C src/_clones/cognitive pull --ff-only origin main git -C src/_clones/pymdp fetch --prune git -C src/_clones/pymdp pull --ff-only origin textbook","title":"Update Clones Safely"},{"location":"clones/#re-clone-when-needed","text":"rm -rf src/_clones/ActiveInference.jl uv run python src/repos/clone_repo.py --url https://github.com/docxology/ActiveInference.jl --dest src/_clones/ActiveInference.jl --branch textbook --shallow","title":"Re-clone When Needed"},{"location":"configuration/","text":"Configuration Reference \u00b6 This page collects configuration examples and CLI snippets. YAML Examples \u00b6 # data/config/entities.yaml - Target learners entities: - name: \"karl_friston\" description: \"Neuroscientist, developer of Free Energy Principle\" category: \"scientist\" priority: \"high\" - name: \"elon_musk\" description: \"CEO of Tesla, SpaceX, and other ventures\" category: \"tech_leader\" priority: \"medium\" # data/config/domains.yaml - Professional domains domains: - name: \"biochemistry\" description: \"Study of chemical processes within living organisms\" category: \"life_sciences\" priority: \"high\" keywords: [\"molecular biology\", \"enzymes\", \"metabolism\"] - name: \"artificial_intelligence\" description: \"Computer systems capable of tasks requiring human intelligence\" category: \"technology\" priority: \"high\" keywords: [\"machine learning\", \"neural networks\", \"robotics\"] CLI Examples \u00b6 # Process only high-priority items python learning/curriculum_creation/1_Research_Entity.py --priority high python learning/curriculum_creation/1_Research_Domain.py --priority high # Filter by professional category python learning/curriculum_creation/1_Research_Domain.py --category life_sciences python learning/curriculum_creation/1_Research_Domain.py --category technology # Process specific targets python learning/curriculum_creation/1_Research_Entity.py --entity karl_friston python learning/curriculum_creation/1_Research_Domain.py --domain biochemistry # Control overwrite behavior python learning/curriculum_creation/1_Research_Domain.py --overwrite # Force overwrite existing # Default: skip existing files automatically Project Structure (High-Level) \u00b6 START/ \u251c\u2500\u2500 src/ # Core system implementation \u251c\u2500\u2500 learning/ # Curriculum creation scripts \u251c\u2500\u2500 data/ # Generated content and configuration \u251c\u2500\u2500 docs/ # Comprehensive documentation \u251c\u2500\u2500 tests/ # Test suite and validation \u2514\u2500\u2500 README.md # Project overview and quick start","title":"Configuration"},{"location":"configuration/#configuration-reference","text":"This page collects configuration examples and CLI snippets.","title":"Configuration Reference"},{"location":"configuration/#yaml-examples","text":"# data/config/entities.yaml - Target learners entities: - name: \"karl_friston\" description: \"Neuroscientist, developer of Free Energy Principle\" category: \"scientist\" priority: \"high\" - name: \"elon_musk\" description: \"CEO of Tesla, SpaceX, and other ventures\" category: \"tech_leader\" priority: \"medium\" # data/config/domains.yaml - Professional domains domains: - name: \"biochemistry\" description: \"Study of chemical processes within living organisms\" category: \"life_sciences\" priority: \"high\" keywords: [\"molecular biology\", \"enzymes\", \"metabolism\"] - name: \"artificial_intelligence\" description: \"Computer systems capable of tasks requiring human intelligence\" category: \"technology\" priority: \"high\" keywords: [\"machine learning\", \"neural networks\", \"robotics\"]","title":"YAML Examples"},{"location":"configuration/#cli-examples","text":"# Process only high-priority items python learning/curriculum_creation/1_Research_Entity.py --priority high python learning/curriculum_creation/1_Research_Domain.py --priority high # Filter by professional category python learning/curriculum_creation/1_Research_Domain.py --category life_sciences python learning/curriculum_creation/1_Research_Domain.py --category technology # Process specific targets python learning/curriculum_creation/1_Research_Entity.py --entity karl_friston python learning/curriculum_creation/1_Research_Domain.py --domain biochemistry # Control overwrite behavior python learning/curriculum_creation/1_Research_Domain.py --overwrite # Force overwrite existing # Default: skip existing files automatically","title":"CLI Examples"},{"location":"configuration/#project-structure-high-level","text":"START/ \u251c\u2500\u2500 src/ # Core system implementation \u251c\u2500\u2500 learning/ # Curriculum creation scripts \u251c\u2500\u2500 data/ # Generated content and configuration \u251c\u2500\u2500 docs/ # Comprehensive documentation \u251c\u2500\u2500 tests/ # Test suite and validation \u2514\u2500\u2500 README.md # Project overview and quick start","title":"Project Structure (High-Level)"},{"location":"conventions/","text":"Documentation Conventions \u00b6 This repository follows a modular, folder-based documentation approach that works both as raw Markdown and as a website (via MkDocs/GitHub Pages). File naming \u00b6 Top-level docs live in docs/ and use clear, task-oriented names: getting_started.md , environment.md , pipeline.md , configuration.md , TESTING.md , examples.md , clones.md , README.md Use lowercase with underscores; reserve uppercase for canonical files like README.md , TESTING.md . Prefer one topic per file; keep files focused and short. Structure (Di\u00e1taxis mapping) \u00b6 Tutorials: getting_started.md , examples embedded in usage guides How-to guides: learning/curriculum_creation/USAGE_GUIDE.md Explanations: pipeline.md , clones.md Reference: environment.md , configuration.md , TESTING.md Links and cross-references \u00b6 Intra-doc links use relative paths (e.g., ./pipeline.md ). Cross-area links should point to learning/ guides where appropriate. Keep Mermaid diagrams minimal and with clickable links when useful. Site generation \u00b6 mkdocs.yml defines navigation mirroring the folder layout. Landing page is docs/index.md , mirroring docs/README.md hub content. Use common Markdown extensions: toc, admonition, tables, codehilite, def_list, footnotes, attr_list. Quality and maintenance \u00b6 Keep docs accurate and updated with changes. Use clear, concise language; avoid jargon. Validate locally with uv run mkdocs serve when editing site structure.","title":"Conventions"},{"location":"conventions/#documentation-conventions","text":"This repository follows a modular, folder-based documentation approach that works both as raw Markdown and as a website (via MkDocs/GitHub Pages).","title":"Documentation Conventions"},{"location":"conventions/#file-naming","text":"Top-level docs live in docs/ and use clear, task-oriented names: getting_started.md , environment.md , pipeline.md , configuration.md , TESTING.md , examples.md , clones.md , README.md Use lowercase with underscores; reserve uppercase for canonical files like README.md , TESTING.md . Prefer one topic per file; keep files focused and short.","title":"File naming"},{"location":"conventions/#structure-diataxis-mapping","text":"Tutorials: getting_started.md , examples embedded in usage guides How-to guides: learning/curriculum_creation/USAGE_GUIDE.md Explanations: pipeline.md , clones.md Reference: environment.md , configuration.md , TESTING.md","title":"Structure (Di\u00e1taxis mapping)"},{"location":"conventions/#links-and-cross-references","text":"Intra-doc links use relative paths (e.g., ./pipeline.md ). Cross-area links should point to learning/ guides where appropriate. Keep Mermaid diagrams minimal and with clickable links when useful.","title":"Links and cross-references"},{"location":"conventions/#site-generation","text":"mkdocs.yml defines navigation mirroring the folder layout. Landing page is docs/index.md , mirroring docs/README.md hub content. Use common Markdown extensions: toc, admonition, tables, codehilite, def_list, footnotes, attr_list.","title":"Site generation"},{"location":"conventions/#quality-and-maintenance","text":"Keep docs accurate and updated with changes. Use clear, concise language; avoid jargon. Validate locally with uv run mkdocs serve when editing site structure.","title":"Quality and maintenance"},{"location":"data_outputs/","text":"Data & Outputs \u00b6 This page summarizes where the system writes artifacts and what each directory contains. Research Artifacts \u00b6 data/ \u251c\u2500\u2500 audience_research/ # Personalized learner/entity profiles (JSON/MD) \u251c\u2500\u2500 domain_research/ # Professional domain analyses (JSON/MD) Audience Research \u00b6 Inputs: entities defined in data/config/entities.yaml Outputs: <Entity>_research_<YYYYMMDD>.{json,md} Domain Research \u00b6 Inputs: domains defined in data/config/domains.yaml Outputs: <Domain>_research_<YYYYMMDD>.{json,md} Curriculum Content \u00b6 data/ \u251c\u2500\u2500 written_curriculums/ # Generated curricula (per domain/entity) \u251c\u2500\u2500 translated_curriculums/ # Multilingual versions by language Written Curriculums \u00b6 Structure: per-domain folders containing section .md files and a summary .json . Example: data/written_curriculums/Coffee Roasting/ Translated Curriculums \u00b6 Structure: language subfolders (e.g., spanish/ , french/ , chinese/ , tagalog/ ). Contents: translated .md sections matching the source curriculum. Visualizations \u00b6 data/visualizations/ \u251c\u2500\u2500 *_flow.mmd # Mermaid flow diagrams \u251c\u2500\u2500 *_section_breakdown.png # Section-level charts \u251c\u2500\u2500 curriculum_metrics.{json,png} # Aggregate metrics \u251c\u2500\u2500 curriculum_structure.mmd # Overall structure diagram Generating Visualizations \u00b6 Run from learning/curriculum_creation/ : uv run python 3_Introduction_Visualizations.py Prompt Templates \u00b6 data/prompts/ \u251c\u2500\u2500 research_domain_analysis.md \u251c\u2500\u2500 research_domain_curriculum.md \u251c\u2500\u2500 research_entity.md \u2514\u2500\u2500 translation.md These drive LLM prompt engineering for research, curriculum, personalization, and translation. Configuration Files \u00b6 data/config/ \u251c\u2500\u2500 entities.yaml \u251c\u2500\u2500 domains.yaml \u2514\u2500\u2500 languages.yaml Use these to control which entities/domains/languages are processed.","title":"Data & Outputs"},{"location":"data_outputs/#data-outputs","text":"This page summarizes where the system writes artifacts and what each directory contains.","title":"Data &amp; Outputs"},{"location":"data_outputs/#research-artifacts","text":"data/ \u251c\u2500\u2500 audience_research/ # Personalized learner/entity profiles (JSON/MD) \u251c\u2500\u2500 domain_research/ # Professional domain analyses (JSON/MD)","title":"Research Artifacts"},{"location":"data_outputs/#audience-research","text":"Inputs: entities defined in data/config/entities.yaml Outputs: <Entity>_research_<YYYYMMDD>.{json,md}","title":"Audience Research"},{"location":"data_outputs/#domain-research","text":"Inputs: domains defined in data/config/domains.yaml Outputs: <Domain>_research_<YYYYMMDD>.{json,md}","title":"Domain Research"},{"location":"data_outputs/#curriculum-content","text":"data/ \u251c\u2500\u2500 written_curriculums/ # Generated curricula (per domain/entity) \u251c\u2500\u2500 translated_curriculums/ # Multilingual versions by language","title":"Curriculum Content"},{"location":"data_outputs/#written-curriculums","text":"Structure: per-domain folders containing section .md files and a summary .json . Example: data/written_curriculums/Coffee Roasting/","title":"Written Curriculums"},{"location":"data_outputs/#translated-curriculums","text":"Structure: language subfolders (e.g., spanish/ , french/ , chinese/ , tagalog/ ). Contents: translated .md sections matching the source curriculum.","title":"Translated Curriculums"},{"location":"data_outputs/#visualizations","text":"data/visualizations/ \u251c\u2500\u2500 *_flow.mmd # Mermaid flow diagrams \u251c\u2500\u2500 *_section_breakdown.png # Section-level charts \u251c\u2500\u2500 curriculum_metrics.{json,png} # Aggregate metrics \u251c\u2500\u2500 curriculum_structure.mmd # Overall structure diagram","title":"Visualizations"},{"location":"data_outputs/#generating-visualizations","text":"Run from learning/curriculum_creation/ : uv run python 3_Introduction_Visualizations.py","title":"Generating Visualizations"},{"location":"data_outputs/#prompt-templates","text":"data/prompts/ \u251c\u2500\u2500 research_domain_analysis.md \u251c\u2500\u2500 research_domain_curriculum.md \u251c\u2500\u2500 research_entity.md \u2514\u2500\u2500 translation.md These drive LLM prompt engineering for research, curriculum, personalization, and translation.","title":"Prompt Templates"},{"location":"data_outputs/#configuration-files","text":"data/config/ \u251c\u2500\u2500 entities.yaml \u251c\u2500\u2500 domains.yaml \u2514\u2500\u2500 languages.yaml Use these to control which entities/domains/languages are processed.","title":"Configuration Files"},{"location":"docs_and_deployment/","text":"Documentation & Deployment \u00b6 This page explains how to build, serve, and deploy the docs site locally and to GitHub Pages. Quick Commands \u00b6 # Serve locally with live reload (opens browser) ./run_docs.sh --serve # Build static site into ./site and open file URL ./run_docs.sh --build # Deploy to GitHub Pages (gh-pages branch) and open Pages URL ./run_docs.sh --deploy The script auto-selects a MkDocs runner in this order: uvx mkdocs , mkdocs , or uv run --with mkdocs --with mkdocs-material mkdocs . GitHub Pages \u00b6 Deploy from Branch \u00b6 The script runs mkdocs gh-deploy --force , publishing to the gh-pages branch. GitHub Pages serves the site from gh-pages automatically when configured to \"Deploy from a branch\". After deploy, the script opens the computed URL: https://<org>.github.io/<repo>/ . Deploy with Actions (Alternative) \u00b6 If you prefer a custom GitHub Actions workflow (checkout \u2192 build \u2192 upload-pages-artifact \u2192 deploy-pages), add a workflow under .github/workflows/pages.yml following GitHub's guide. The local script remains useful for previewing changes and local development. Reference: GitHub Docs \u2014 Publishing with a custom GitHub Actions workflow. Troubleshooting \u00b6 If mkdocs is not installed, the script falls back to uvx or a temporary uv run install. Ensure mkdocs.yml exists at the repo root. Conflicts warning (README vs index): ensure only one maps to the root path in nav .","title":"Docs & Deployment"},{"location":"docs_and_deployment/#documentation-deployment","text":"This page explains how to build, serve, and deploy the docs site locally and to GitHub Pages.","title":"Documentation &amp; Deployment"},{"location":"docs_and_deployment/#quick-commands","text":"# Serve locally with live reload (opens browser) ./run_docs.sh --serve # Build static site into ./site and open file URL ./run_docs.sh --build # Deploy to GitHub Pages (gh-pages branch) and open Pages URL ./run_docs.sh --deploy The script auto-selects a MkDocs runner in this order: uvx mkdocs , mkdocs , or uv run --with mkdocs --with mkdocs-material mkdocs .","title":"Quick Commands"},{"location":"docs_and_deployment/#github-pages","text":"","title":"GitHub Pages"},{"location":"docs_and_deployment/#deploy-from-branch","text":"The script runs mkdocs gh-deploy --force , publishing to the gh-pages branch. GitHub Pages serves the site from gh-pages automatically when configured to \"Deploy from a branch\". After deploy, the script opens the computed URL: https://<org>.github.io/<repo>/ .","title":"Deploy from Branch"},{"location":"docs_and_deployment/#deploy-with-actions-alternative","text":"If you prefer a custom GitHub Actions workflow (checkout \u2192 build \u2192 upload-pages-artifact \u2192 deploy-pages), add a workflow under .github/workflows/pages.yml following GitHub's guide. The local script remains useful for previewing changes and local development. Reference: GitHub Docs \u2014 Publishing with a custom GitHub Actions workflow.","title":"Deploy with Actions (Alternative)"},{"location":"docs_and_deployment/#troubleshooting","text":"If mkdocs is not installed, the script falls back to uvx or a temporary uv run install. Ensure mkdocs.yml exists at the repo root. Conflicts warning (README vs index): ensure only one maps to the root path in nav .","title":"Troubleshooting"},{"location":"environment/","text":"Environment Setup & Development Guide \u00b6 Prerequisites \u00b6 System Requirements \u00b6 Python 3.10+ (3.11+ recommended for optimal performance) uv package manager ( astral.sh/uv ) Git for repository management and cloning external resources Internet connection for API access (Perplexity, OpenRouter) API Access Requirements \u00b6 Perplexity API account and key for real-time research OpenRouter API account and key for advanced LLM-based content generation Optional : OpenAI API key for alternative LLM access Quick Installation \u00b6 flowchart LR A[Install uv] --> B[Clone repo] B --> C[uv sync --all-extras --dev] C --> D[Configure .env] D --> E[Download spaCy models] E --> F[Verify imports/PYTHONPATH] F --> G[Run tests] G --> H[Run ruff & black] H --> I[Ready for development] click G \"./TESTING.md\" \"Testing Guide\" click I \"./README.md\" \"Docs Hub\" 1. Install uv Package Manager \u00b6 curl -LsSf https://astral.sh/uv/install.sh | sh # or on macOS: brew install uv 2. Install Project Dependencies \u00b6 # Install all dependencies including development tools uv sync --all-extras --dev # Install specific dependency groups uv sync --extra visualization --extra translation --dev 3. Download Required Models \u00b6 # spaCy model for natural language processing uv run python -m spacy download en_core_web_sm # Additional language models for multilingual support (optional) uv run python -m spacy download fr_core_news_sm # French uv run python -m spacy download es_core_news_sm # Spanish Configuration \u00b6 1. Environment Variables Setup \u00b6 # Copy the example environment file cp .env.example .env # Edit with your API keys and configuration $EDITOR .env 2. Required Environment Variables \u00b6 # Required API Keys PERPLEXITY_API_KEY=your_perplexity_api_key_here OPENROUTER_API_KEY=your_openrouter_api_key_here # Optional API Keys OPENAI_API_KEY=your_openai_api_key_here # Default Model Configuration PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online OPENROUTER_MODEL=gpt-4o-mini-2024-07-18 OPENAI_MODEL=gpt-4o-mini 3. Configuration Files \u00b6 The system uses YAML configuration files in data/config/ : - entities.yaml - Target learner profiles and research subjects - domains.yaml - Professional domains for curriculum development - languages.yaml - Translation targets and language mappings Development Workflow \u00b6 Code Quality & Testing \u00b6 # Run comprehensive test suite uv run pytest -q # Code linting and formatting uv run ruff check . # Lint checking uv run black --check . # Format checking uv run black . # Auto-formatting # Type checking (if configured) uv run mypy src/ Curriculum Pipeline Development \u00b6 # Set Python path for development export PYTHONPATH=/path/to/project:$PYTHONPATH # Run curriculum creation scripts cd learning/curriculum_creation/ uv run python 1_Research_Domain.py --help uv run python 1_Research_Entity.py --priority high Testing API Integration \u00b6 # Test Perplexity API connection uv run python -c \" from src.perplexity.clients import build_perplexity_client client = build_perplexity_client() print('Perplexity API connection successful') \" # Test OpenRouter API connection uv run python -c \" from src.perplexity.clients import build_openrouter_client client = build_openrouter_client() print('OpenRouter API connection successful') \" Project Structure \u00b6 Core Development Directories \u00b6 src/ \u251c\u2500\u2500 common/ # Shared utilities and infrastructure \u2502 \u251c\u2500\u2500 config.py # Configuration management \u2502 \u251c\u2500\u2500 io.py # File I/O operations \u2502 \u251c\u2500\u2500 logging_utils.py # Structured logging \u2502 \u251c\u2500\u2500 paths.py # Path management \u2502 \u2514\u2500\u2500 prompts.py # Prompt template system \u251c\u2500\u2500 perplexity/ # Perplexity API integration \u2502 \u251c\u2500\u2500 clients.py # API client management \u2502 \u251c\u2500\u2500 domain.py # Domain research \u2502 \u251c\u2500\u2500 entity.py # Entity/audience research \u2502 \u251c\u2500\u2500 curriculum.py # Curriculum generation \u2502 \u2514\u2500\u2500 translation.py # Multilingual content \u251c\u2500\u2500 config/ # Configuration utilities \u2514\u2500\u2500 visualization/ # Chart and diagram generation Data and Configuration \u00b6 data/ \u251c\u2500\u2500 config/ # YAML configuration files \u251c\u2500\u2500 prompts/ # LLM prompt templates \u251c\u2500\u2500 audience_research/ # Generated entity research \u251c\u2500\u2500 domain_research/ # Generated domain analysis \u251c\u2500\u2500 written_curriculums/ # Generated curriculum content \u251c\u2500\u2500 translated_curriculums/ # Multilingual versions \u2514\u2500\u2500 visualizations/ # Charts and diagrams Learning and Documentation \u00b6 learning/curriculum_creation/ # Main curriculum creation scripts docs/ # Comprehensive documentation tests/ # Test suite and fixtures Advanced Setup \u00b6 Performance Optimization \u00b6 # Enable faster JSON processing pip install orjson # GPU acceleration for visualization (optional) pip install matplotlib[gpu] # Parallel processing enhancements pip install joblib multiprocessing-logging Development Tools \u00b6 # Install additional development tools uv add --dev pre-commit jupyter lab ipython # Set up pre-commit hooks pre-commit install IDE Integration \u00b6 VS Code : Install Python, Pylance, and Black formatter extensions PyCharm : Configure interpreters to use uv virtual environment Jupyter : Use uv run jupyter lab for notebook development Troubleshooting \u00b6 Common Issues \u00b6 API Key Issues \u00b6 # Verify API keys are loaded uv run python -c \"import os; print('PERPLEXITY_API_KEY:', bool(os.getenv('PERPLEXITY_API_KEY')))\" Import Errors \u00b6 # Ensure PYTHONPATH is set correctly export PYTHONPATH=$(pwd):$PYTHONPATH uv run python -c \"import src.common.paths; print('Import successful')\" Dependency Issues \u00b6 # Force reinstall dependencies uv sync --reinstall # Check for conflicts uv tree Performance Considerations \u00b6 API Rate Limits : Respect Perplexity and OpenRouter rate limits Memory Usage : Large curriculum generation may require 4GB+ RAM Storage : Generated content can be substantial; ensure adequate disk space Getting Help \u00b6 Documentation : Check docs/ directory for detailed guides Tests : Review tests/ for usage examples Issues : Check project issues for known problems and solutions Continuous Integration (CI) \u00b6 The default CI workflow mirrors local quality checks. To emulate CI locally: uv sync --all-extras --dev uv run pytest -q uv run ruff check . uv run black --check . sequenceDiagram participant Dev as Developer participant CI as CI Runner Dev->>CI: Push branch/PR CI->>CI: uv sync --all-extras --dev CI->>CI: uv run pytest -q CI->>CI: uv run ruff check . CI->>CI: uv run black --check . CI-->>Dev: Status & reports See also: Testing policy and markers in docs/TESTING.md .","title":"Environment"},{"location":"environment/#environment-setup-development-guide","text":"","title":"Environment Setup &amp; Development Guide"},{"location":"environment/#prerequisites","text":"","title":"Prerequisites"},{"location":"environment/#system-requirements","text":"Python 3.10+ (3.11+ recommended for optimal performance) uv package manager ( astral.sh/uv ) Git for repository management and cloning external resources Internet connection for API access (Perplexity, OpenRouter)","title":"System Requirements"},{"location":"environment/#api-access-requirements","text":"Perplexity API account and key for real-time research OpenRouter API account and key for advanced LLM-based content generation Optional : OpenAI API key for alternative LLM access","title":"API Access Requirements"},{"location":"environment/#quick-installation","text":"flowchart LR A[Install uv] --> B[Clone repo] B --> C[uv sync --all-extras --dev] C --> D[Configure .env] D --> E[Download spaCy models] E --> F[Verify imports/PYTHONPATH] F --> G[Run tests] G --> H[Run ruff & black] H --> I[Ready for development] click G \"./TESTING.md\" \"Testing Guide\" click I \"./README.md\" \"Docs Hub\"","title":"Quick Installation"},{"location":"environment/#1-install-uv-package-manager","text":"curl -LsSf https://astral.sh/uv/install.sh | sh # or on macOS: brew install uv","title":"1. Install uv Package Manager"},{"location":"environment/#2-install-project-dependencies","text":"# Install all dependencies including development tools uv sync --all-extras --dev # Install specific dependency groups uv sync --extra visualization --extra translation --dev","title":"2. Install Project Dependencies"},{"location":"environment/#3-download-required-models","text":"# spaCy model for natural language processing uv run python -m spacy download en_core_web_sm # Additional language models for multilingual support (optional) uv run python -m spacy download fr_core_news_sm # French uv run python -m spacy download es_core_news_sm # Spanish","title":"3. Download Required Models"},{"location":"environment/#configuration","text":"","title":"Configuration"},{"location":"environment/#1-environment-variables-setup","text":"# Copy the example environment file cp .env.example .env # Edit with your API keys and configuration $EDITOR .env","title":"1. Environment Variables Setup"},{"location":"environment/#2-required-environment-variables","text":"# Required API Keys PERPLEXITY_API_KEY=your_perplexity_api_key_here OPENROUTER_API_KEY=your_openrouter_api_key_here # Optional API Keys OPENAI_API_KEY=your_openai_api_key_here # Default Model Configuration PERPLEXITY_MODEL=llama-3.1-sonar-small-128k-online OPENROUTER_MODEL=gpt-4o-mini-2024-07-18 OPENAI_MODEL=gpt-4o-mini","title":"2. Required Environment Variables"},{"location":"environment/#3-configuration-files","text":"The system uses YAML configuration files in data/config/ : - entities.yaml - Target learner profiles and research subjects - domains.yaml - Professional domains for curriculum development - languages.yaml - Translation targets and language mappings","title":"3. Configuration Files"},{"location":"environment/#development-workflow","text":"","title":"Development Workflow"},{"location":"environment/#code-quality-testing","text":"# Run comprehensive test suite uv run pytest -q # Code linting and formatting uv run ruff check . # Lint checking uv run black --check . # Format checking uv run black . # Auto-formatting # Type checking (if configured) uv run mypy src/","title":"Code Quality &amp; Testing"},{"location":"environment/#curriculum-pipeline-development","text":"# Set Python path for development export PYTHONPATH=/path/to/project:$PYTHONPATH # Run curriculum creation scripts cd learning/curriculum_creation/ uv run python 1_Research_Domain.py --help uv run python 1_Research_Entity.py --priority high","title":"Curriculum Pipeline Development"},{"location":"environment/#testing-api-integration","text":"# Test Perplexity API connection uv run python -c \" from src.perplexity.clients import build_perplexity_client client = build_perplexity_client() print('Perplexity API connection successful') \" # Test OpenRouter API connection uv run python -c \" from src.perplexity.clients import build_openrouter_client client = build_openrouter_client() print('OpenRouter API connection successful') \"","title":"Testing API Integration"},{"location":"environment/#project-structure","text":"","title":"Project Structure"},{"location":"environment/#core-development-directories","text":"src/ \u251c\u2500\u2500 common/ # Shared utilities and infrastructure \u2502 \u251c\u2500\u2500 config.py # Configuration management \u2502 \u251c\u2500\u2500 io.py # File I/O operations \u2502 \u251c\u2500\u2500 logging_utils.py # Structured logging \u2502 \u251c\u2500\u2500 paths.py # Path management \u2502 \u2514\u2500\u2500 prompts.py # Prompt template system \u251c\u2500\u2500 perplexity/ # Perplexity API integration \u2502 \u251c\u2500\u2500 clients.py # API client management \u2502 \u251c\u2500\u2500 domain.py # Domain research \u2502 \u251c\u2500\u2500 entity.py # Entity/audience research \u2502 \u251c\u2500\u2500 curriculum.py # Curriculum generation \u2502 \u2514\u2500\u2500 translation.py # Multilingual content \u251c\u2500\u2500 config/ # Configuration utilities \u2514\u2500\u2500 visualization/ # Chart and diagram generation","title":"Core Development Directories"},{"location":"environment/#data-and-configuration","text":"data/ \u251c\u2500\u2500 config/ # YAML configuration files \u251c\u2500\u2500 prompts/ # LLM prompt templates \u251c\u2500\u2500 audience_research/ # Generated entity research \u251c\u2500\u2500 domain_research/ # Generated domain analysis \u251c\u2500\u2500 written_curriculums/ # Generated curriculum content \u251c\u2500\u2500 translated_curriculums/ # Multilingual versions \u2514\u2500\u2500 visualizations/ # Charts and diagrams","title":"Data and Configuration"},{"location":"environment/#learning-and-documentation","text":"learning/curriculum_creation/ # Main curriculum creation scripts docs/ # Comprehensive documentation tests/ # Test suite and fixtures","title":"Learning and Documentation"},{"location":"environment/#advanced-setup","text":"","title":"Advanced Setup"},{"location":"environment/#performance-optimization","text":"# Enable faster JSON processing pip install orjson # GPU acceleration for visualization (optional) pip install matplotlib[gpu] # Parallel processing enhancements pip install joblib multiprocessing-logging","title":"Performance Optimization"},{"location":"environment/#development-tools","text":"# Install additional development tools uv add --dev pre-commit jupyter lab ipython # Set up pre-commit hooks pre-commit install","title":"Development Tools"},{"location":"environment/#ide-integration","text":"VS Code : Install Python, Pylance, and Black formatter extensions PyCharm : Configure interpreters to use uv virtual environment Jupyter : Use uv run jupyter lab for notebook development","title":"IDE Integration"},{"location":"environment/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"environment/#common-issues","text":"","title":"Common Issues"},{"location":"environment/#api-key-issues","text":"# Verify API keys are loaded uv run python -c \"import os; print('PERPLEXITY_API_KEY:', bool(os.getenv('PERPLEXITY_API_KEY')))\"","title":"API Key Issues"},{"location":"environment/#import-errors","text":"# Ensure PYTHONPATH is set correctly export PYTHONPATH=$(pwd):$PYTHONPATH uv run python -c \"import src.common.paths; print('Import successful')\"","title":"Import Errors"},{"location":"environment/#dependency-issues","text":"# Force reinstall dependencies uv sync --reinstall # Check for conflicts uv tree","title":"Dependency Issues"},{"location":"environment/#performance-considerations","text":"API Rate Limits : Respect Perplexity and OpenRouter rate limits Memory Usage : Large curriculum generation may require 4GB+ RAM Storage : Generated content can be substantial; ensure adequate disk space","title":"Performance Considerations"},{"location":"environment/#getting-help","text":"Documentation : Check docs/ directory for detailed guides Tests : Review tests/ for usage examples Issues : Check project issues for known problems and solutions","title":"Getting Help"},{"location":"environment/#continuous-integration-ci","text":"The default CI workflow mirrors local quality checks. To emulate CI locally: uv sync --all-extras --dev uv run pytest -q uv run ruff check . uv run black --check . sequenceDiagram participant Dev as Developer participant CI as CI Runner Dev->>CI: Push branch/PR CI->>CI: uv sync --all-extras --dev CI->>CI: uv run pytest -q CI->>CI: uv run ruff check . CI->>CI: uv run black --check . CI-->>Dev: Status & reports See also: Testing policy and markers in docs/TESTING.md .","title":"Continuous Integration (CI)"},{"location":"examples/","text":"Examples & Outputs \u00b6 Real examples of generated artifacts and locations. Research Outputs \u00b6 # Domain research (example) ls data/domain_research/ # Audience research (example) ls data/audience_research/ Curriculum & Visualizations \u00b6 # Curriculum content ls data/written_curriculums/ # Visualizations ls data/visualizations/ Multilingual Content \u00b6 ls data/translated_curriculums/","title":"Examples"},{"location":"examples/#examples-outputs","text":"Real examples of generated artifacts and locations.","title":"Examples &amp; Outputs"},{"location":"examples/#research-outputs","text":"# Domain research (example) ls data/domain_research/ # Audience research (example) ls data/audience_research/","title":"Research Outputs"},{"location":"examples/#curriculum-visualizations","text":"# Curriculum content ls data/written_curriculums/ # Visualizations ls data/visualizations/","title":"Curriculum &amp; Visualizations"},{"location":"examples/#multilingual-content","text":"ls data/translated_curriculums/","title":"Multilingual Content"},{"location":"getting_started/","text":"Getting Started \u00b6 Use this guide to install, run your first research session, and explore outputs. Prerequisites \u00b6 See Environment Setup for full details: docs/environment.md . Quick Installation \u00b6 # Install uv package manager curl -LsSf https://astral.sh/uv/install.sh | sh # Clone and set up project git clone https://github.com/ActiveInferenceInstitute/Start.git cd Start # Install dependencies uv sync --all-extras --dev # Download language models uv run python -m spacy download en_core_web_sm # Configure API keys cp .env.example .env $EDITOR .env # Add PERPLEXITY_API_KEY and OPENROUTER_API_KEY # Verify installation uv run pytest -q uv run ruff check . uv run black --check . First Research Session \u00b6 # Ensure imports work export PYTHONPATH=$(pwd):$PYTHONPATH # Research a domain (creates comprehensive analysis) uv run python learning/curriculum_creation/1_Research_Domain.py --domain biochemistry # Research an entity (creates personalized profile) uv run python learning/curriculum_creation/1_Research_Entity.py --entity karl_friston Generate Curriculum and Visualizations \u00b6 # Generate curricula from research (40-60 hour programs) uv run python learning/curriculum_creation/2_Write_Introduction.py # Create visualizations (PNG charts + Mermaid diagrams) uv run python learning/curriculum_creation/3_Introduction_Visualizations.py # Translate to multiple languages (with cultural adaptation) uv run python learning/curriculum_creation/4_Translate_Introductions.py --languages Spanish French Explore Generated Content \u00b6 # Check generated research ls data/domain_research/ # Domain analyses ls data/audience_research/ # Entity profiles # Check curriculum content ls data/written_curriculums/ # Generated curricula ls data/visualizations/ # Charts and diagrams ls data/translated_curriculums/ # Multilingual content Common CLI Commands \u00b6 # Research high-priority entities python learning/curriculum_creation/1_Research_Entity.py --priority high # Research specific domain with overwrite python learning/curriculum_creation/1_Research_Domain.py --domain biochemistry --overwrite # Filter by category and priority python learning/curriculum_creation/1_Research_Domain.py --category life_sciences --priority high # Generate multilingual content python learning/curriculum_creation/4_Translate_Introductions.py --languages Spanish French German","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"Use this guide to install, run your first research session, and explore outputs.","title":"Getting Started"},{"location":"getting_started/#prerequisites","text":"See Environment Setup for full details: docs/environment.md .","title":"Prerequisites"},{"location":"getting_started/#quick-installation","text":"# Install uv package manager curl -LsSf https://astral.sh/uv/install.sh | sh # Clone and set up project git clone https://github.com/ActiveInferenceInstitute/Start.git cd Start # Install dependencies uv sync --all-extras --dev # Download language models uv run python -m spacy download en_core_web_sm # Configure API keys cp .env.example .env $EDITOR .env # Add PERPLEXITY_API_KEY and OPENROUTER_API_KEY # Verify installation uv run pytest -q uv run ruff check . uv run black --check .","title":"Quick Installation"},{"location":"getting_started/#first-research-session","text":"# Ensure imports work export PYTHONPATH=$(pwd):$PYTHONPATH # Research a domain (creates comprehensive analysis) uv run python learning/curriculum_creation/1_Research_Domain.py --domain biochemistry # Research an entity (creates personalized profile) uv run python learning/curriculum_creation/1_Research_Entity.py --entity karl_friston","title":"First Research Session"},{"location":"getting_started/#generate-curriculum-and-visualizations","text":"# Generate curricula from research (40-60 hour programs) uv run python learning/curriculum_creation/2_Write_Introduction.py # Create visualizations (PNG charts + Mermaid diagrams) uv run python learning/curriculum_creation/3_Introduction_Visualizations.py # Translate to multiple languages (with cultural adaptation) uv run python learning/curriculum_creation/4_Translate_Introductions.py --languages Spanish French","title":"Generate Curriculum and Visualizations"},{"location":"getting_started/#explore-generated-content","text":"# Check generated research ls data/domain_research/ # Domain analyses ls data/audience_research/ # Entity profiles # Check curriculum content ls data/written_curriculums/ # Generated curricula ls data/visualizations/ # Charts and diagrams ls data/translated_curriculums/ # Multilingual content","title":"Explore Generated Content"},{"location":"getting_started/#common-cli-commands","text":"# Research high-priority entities python learning/curriculum_creation/1_Research_Entity.py --priority high # Research specific domain with overwrite python learning/curriculum_creation/1_Research_Domain.py --domain biochemistry --overwrite # Filter by category and priority python learning/curriculum_creation/1_Research_Domain.py --category life_sciences --priority high # Generate multilingual content python learning/curriculum_creation/4_Translate_Introductions.py --languages Spanish French German","title":"Common CLI Commands"},{"location":"pipeline/","text":"Active Inference Curriculum Creation Pipeline \u00b6 Overview \u00b6 The START project provides a comprehensive, AI-powered pipeline for creating personalized Active Inference and Free Energy Principle curricula. The system uses real-time research via Perplexity API and advanced LLM-based content generation to produce professional-grade educational materials. Pipeline Stages \u00b6 flowchart TD A[Configuration YAMLs] --> B[Research] B --> C[Curriculum Generation] C --> D[Visualization] D --> E[Translation] E --> F[Outputs] subgraph Inputs A1[data/config/entities.yaml] A2[data/config/domains.yaml] A3[data/config/languages.yaml] end A1 --> A A2 --> A A3 --> A click A1 \"../data/config/entities.yaml\" \"Entities config\" click A2 \"../data/config/domains.yaml\" \"Domains config\" click A3 \"../data/config/languages.yaml\" \"Languages config\" 1. Research Phase \ud83d\udd0d \u00b6 Domain Research : Analyze professional domains (biochemistry, AI, neuroscience, etc.) Entity Research : Create personalized profiles for target learners Configuration-Driven : Uses YAML configs for scalable, organized research 2. Curriculum Generation \u270d\ufe0f \u00b6 Comprehensive Content : 40-60 hour professional development programs Personalized : Tailored to specific domains and individual learning profiles Structured Modules : Multi-section educational frameworks with assessments 3. Visualization Creation \ud83d\udcca \u00b6 Data Visualizations : PNG charts showing curriculum metrics and analysis Process Diagrams : Mermaid diagrams for curriculum structure and flow Interactive Elements : Visual learning aids and conceptual frameworks 4. Multilingual Translation \ud83c\udf0d \u00b6 Cultural Adaptation : Full localization beyond literal translation Professional Quality : Native-speaker level fluency with technical accuracy Multiple Languages : Support for 9+ target languages with script mapping Script Entrypoints \u00b6 Core Curriculum Creation Scripts \u00b6 # Configuration-based research (NEW APPROACH) learning/curriculum_creation/1_Research_Domain.py # Domain analysis learning/curriculum_creation/1_Research_Entity.py # Audience profiling learning/curriculum_creation/2_Write_Introduction.py # Curriculum generation learning/curriculum_creation/3_Introduction_Visualizations.py # Charts & diagrams learning/curriculum_creation/4_Translate_Introductions.py # Multilingual output Supporting Infrastructure \u00b6 src/perplexity/ # Perplexity API integration src/common/ # Shared utilities (paths, config, prompts) src/config/ # Configuration management src/visualization/ # Visualization generation Data Architecture \u00b6 Input Configuration \u00b6 data/config/ \u251c\u2500\u2500 entities.yaml # Target learner profiles (8 entities) \u251c\u2500\u2500 domains.yaml # Professional domains (16 domains) \u2514\u2500\u2500 languages.yaml # Translation targets (9+ languages) Research Outputs \u00b6 data/ \u251c\u2500\u2500 audience_research/ # Personalized learner analysis \u251c\u2500\u2500 domain_research/ # Professional domain analysis \u251c\u2500\u2500 written_curriculums/ # Generated curriculum content \u251c\u2500\u2500 translated_curriculums/ # Multilingual versions \u2514\u2500\u2500 visualizations/ # Charts and diagrams Template System \u00b6 data/prompts/ \u251c\u2500\u2500 research_domain_analysis.md # 6-section domain framework \u251c\u2500\u2500 research_domain_curriculum.md # 9-section curriculum generation \u251c\u2500\u2500 research_entity.md # 6-section personalization \u251c\u2500\u2500 curriculum_section.md # Comprehensive module creation \u2514\u2500\u2500 translation.md # 7-section multilingual framework Enhanced Features \u00b6 Configuration-Driven Research \u00b6 YAML-Based Control : All research targets defined in configuration files Priority Filtering : Process high/medium/low priority items Category Filtering : Focus on specific domain categories Overwrite Control : Skip existing by default, force overwrite with flags Advanced Command-Line Interface \u00b6 # Filter by priority and category python 1_Research_Domain.py --priority high --category life_sciences # Process specific targets python 1_Research_Entity.py --entity karl_friston --overwrite # Multilingual output with specific languages python 4_Translate_Introductions.py --languages Spanish French German Comprehensive Content Generation \u00b6 Domain Analysis : 3,000-5,000 word professional landscape analysis Curriculum Content : 40-60 hour structured learning programs Personalization : 5,000-8,000 word tailored learning strategies Section Modules : 3-5 hour comprehensive learning units API Integration \u00b6 Perplexity API (Research) \u00b6 Real-time Research : Current online information and analysis Professional Insights : Industry trends, challenges, opportunities Comprehensive Analysis : Multi-perspective domain understanding OpenRouter API (Content Generation) \u00b6 Advanced LLMs : High-quality curriculum and translation generation Structured Output : Consistent, professional educational content Multilingual Capability : Native-quality translations with cultural adaptation Quality Assurance \u00b6 Content Standards \u00b6 Professional Grade : University course and corporate training quality Evidence-Based : Real research and current industry insights Comprehensive Coverage : Multi-modal learning approaches Assessment Integrated : Built-in evaluation and progress tracking Technical Standards \u00b6 Modular Architecture : Clean, maintainable, testable code Error Handling : Robust failure recovery and logging Performance Optimized : Efficient API usage and data processing Standards Compliant : Following Python best practices and project conventions Cross-References \u00b6 Environment setup and CI workflow: docs/environment.md Testing policy and markers: docs/TESTING.md Clone management for optional resources: docs/clones.md","title":"Pipeline"},{"location":"pipeline/#active-inference-curriculum-creation-pipeline","text":"","title":"Active Inference Curriculum Creation Pipeline"},{"location":"pipeline/#overview","text":"The START project provides a comprehensive, AI-powered pipeline for creating personalized Active Inference and Free Energy Principle curricula. The system uses real-time research via Perplexity API and advanced LLM-based content generation to produce professional-grade educational materials.","title":"Overview"},{"location":"pipeline/#pipeline-stages","text":"flowchart TD A[Configuration YAMLs] --> B[Research] B --> C[Curriculum Generation] C --> D[Visualization] D --> E[Translation] E --> F[Outputs] subgraph Inputs A1[data/config/entities.yaml] A2[data/config/domains.yaml] A3[data/config/languages.yaml] end A1 --> A A2 --> A A3 --> A click A1 \"../data/config/entities.yaml\" \"Entities config\" click A2 \"../data/config/domains.yaml\" \"Domains config\" click A3 \"../data/config/languages.yaml\" \"Languages config\"","title":"Pipeline Stages"},{"location":"pipeline/#1-research-phase","text":"Domain Research : Analyze professional domains (biochemistry, AI, neuroscience, etc.) Entity Research : Create personalized profiles for target learners Configuration-Driven : Uses YAML configs for scalable, organized research","title":"1. Research Phase \ud83d\udd0d"},{"location":"pipeline/#2-curriculum-generation","text":"Comprehensive Content : 40-60 hour professional development programs Personalized : Tailored to specific domains and individual learning profiles Structured Modules : Multi-section educational frameworks with assessments","title":"2. Curriculum Generation \u270d\ufe0f"},{"location":"pipeline/#3-visualization-creation","text":"Data Visualizations : PNG charts showing curriculum metrics and analysis Process Diagrams : Mermaid diagrams for curriculum structure and flow Interactive Elements : Visual learning aids and conceptual frameworks","title":"3. Visualization Creation \ud83d\udcca"},{"location":"pipeline/#4-multilingual-translation","text":"Cultural Adaptation : Full localization beyond literal translation Professional Quality : Native-speaker level fluency with technical accuracy Multiple Languages : Support for 9+ target languages with script mapping","title":"4. Multilingual Translation \ud83c\udf0d"},{"location":"pipeline/#script-entrypoints","text":"","title":"Script Entrypoints"},{"location":"pipeline/#core-curriculum-creation-scripts","text":"# Configuration-based research (NEW APPROACH) learning/curriculum_creation/1_Research_Domain.py # Domain analysis learning/curriculum_creation/1_Research_Entity.py # Audience profiling learning/curriculum_creation/2_Write_Introduction.py # Curriculum generation learning/curriculum_creation/3_Introduction_Visualizations.py # Charts & diagrams learning/curriculum_creation/4_Translate_Introductions.py # Multilingual output","title":"Core Curriculum Creation Scripts"},{"location":"pipeline/#supporting-infrastructure","text":"src/perplexity/ # Perplexity API integration src/common/ # Shared utilities (paths, config, prompts) src/config/ # Configuration management src/visualization/ # Visualization generation","title":"Supporting Infrastructure"},{"location":"pipeline/#data-architecture","text":"","title":"Data Architecture"},{"location":"pipeline/#input-configuration","text":"data/config/ \u251c\u2500\u2500 entities.yaml # Target learner profiles (8 entities) \u251c\u2500\u2500 domains.yaml # Professional domains (16 domains) \u2514\u2500\u2500 languages.yaml # Translation targets (9+ languages)","title":"Input Configuration"},{"location":"pipeline/#research-outputs","text":"data/ \u251c\u2500\u2500 audience_research/ # Personalized learner analysis \u251c\u2500\u2500 domain_research/ # Professional domain analysis \u251c\u2500\u2500 written_curriculums/ # Generated curriculum content \u251c\u2500\u2500 translated_curriculums/ # Multilingual versions \u2514\u2500\u2500 visualizations/ # Charts and diagrams","title":"Research Outputs"},{"location":"pipeline/#template-system","text":"data/prompts/ \u251c\u2500\u2500 research_domain_analysis.md # 6-section domain framework \u251c\u2500\u2500 research_domain_curriculum.md # 9-section curriculum generation \u251c\u2500\u2500 research_entity.md # 6-section personalization \u251c\u2500\u2500 curriculum_section.md # Comprehensive module creation \u2514\u2500\u2500 translation.md # 7-section multilingual framework","title":"Template System"},{"location":"pipeline/#enhanced-features","text":"","title":"Enhanced Features"},{"location":"pipeline/#configuration-driven-research","text":"YAML-Based Control : All research targets defined in configuration files Priority Filtering : Process high/medium/low priority items Category Filtering : Focus on specific domain categories Overwrite Control : Skip existing by default, force overwrite with flags","title":"Configuration-Driven Research"},{"location":"pipeline/#advanced-command-line-interface","text":"# Filter by priority and category python 1_Research_Domain.py --priority high --category life_sciences # Process specific targets python 1_Research_Entity.py --entity karl_friston --overwrite # Multilingual output with specific languages python 4_Translate_Introductions.py --languages Spanish French German","title":"Advanced Command-Line Interface"},{"location":"pipeline/#comprehensive-content-generation","text":"Domain Analysis : 3,000-5,000 word professional landscape analysis Curriculum Content : 40-60 hour structured learning programs Personalization : 5,000-8,000 word tailored learning strategies Section Modules : 3-5 hour comprehensive learning units","title":"Comprehensive Content Generation"},{"location":"pipeline/#api-integration","text":"","title":"API Integration"},{"location":"pipeline/#perplexity-api-research","text":"Real-time Research : Current online information and analysis Professional Insights : Industry trends, challenges, opportunities Comprehensive Analysis : Multi-perspective domain understanding","title":"Perplexity API (Research)"},{"location":"pipeline/#openrouter-api-content-generation","text":"Advanced LLMs : High-quality curriculum and translation generation Structured Output : Consistent, professional educational content Multilingual Capability : Native-quality translations with cultural adaptation","title":"OpenRouter API (Content Generation)"},{"location":"pipeline/#quality-assurance","text":"","title":"Quality Assurance"},{"location":"pipeline/#content-standards","text":"Professional Grade : University course and corporate training quality Evidence-Based : Real research and current industry insights Comprehensive Coverage : Multi-modal learning approaches Assessment Integrated : Built-in evaluation and progress tracking","title":"Content Standards"},{"location":"pipeline/#technical-standards","text":"Modular Architecture : Clean, maintainable, testable code Error Handling : Robust failure recovery and logging Performance Optimized : Efficient API usage and data processing Standards Compliant : Following Python best practices and project conventions","title":"Technical Standards"},{"location":"pipeline/#cross-references","text":"Environment setup and CI workflow: docs/environment.md Testing policy and markers: docs/TESTING.md Clone management for optional resources: docs/clones.md","title":"Cross-References"},{"location":"translations/","text":"Translations & Localization \u00b6 How multilingual outputs are generated and organized. Overview \u00b6 The system supports 9+ target languages with cultural adaptation, driven by data/config/languages.yaml and the translation prompt template. Run Translation \u00b6 From learning/curriculum_creation/ : uv run python 4_Translate_Introductions.py --languages Spanish French Chinese If omitted, the script may default to languages defined in data/config/languages.yaml . Outputs \u00b6 Artifacts are organized under data/translated_curriculums/ by language: data/translated_curriculums/ \u251c\u2500\u2500 spanish/ \u251c\u2500\u2500 french/ \u251c\u2500\u2500 chinese/ \u2514\u2500\u2500 tagalog/ Each language folder mirrors the source curriculum file structure and filenames. Prompt Template \u00b6 Translation guidance lives in: data/prompts/translation.md This template ensures tone, terminology, and cultural appropriateness while preserving technical accuracy.","title":"Translations"},{"location":"translations/#translations-localization","text":"How multilingual outputs are generated and organized.","title":"Translations &amp; Localization"},{"location":"translations/#overview","text":"The system supports 9+ target languages with cultural adaptation, driven by data/config/languages.yaml and the translation prompt template.","title":"Overview"},{"location":"translations/#run-translation","text":"From learning/curriculum_creation/ : uv run python 4_Translate_Introductions.py --languages Spanish French Chinese If omitted, the script may default to languages defined in data/config/languages.yaml .","title":"Run Translation"},{"location":"translations/#outputs","text":"Artifacts are organized under data/translated_curriculums/ by language: data/translated_curriculums/ \u251c\u2500\u2500 spanish/ \u251c\u2500\u2500 french/ \u251c\u2500\u2500 chinese/ \u2514\u2500\u2500 tagalog/ Each language folder mirrors the source curriculum file structure and filenames.","title":"Outputs"},{"location":"translations/#prompt-template","text":"Translation guidance lives in: data/prompts/translation.md This template ensures tone, terminology, and cultural appropriateness while preserving technical accuracy.","title":"Prompt Template"},{"location":"visualizations/","text":"Visualizations \u00b6 Gallery and references for generated diagrams and charts. Flow Diagrams (Mermaid) \u00b6 The pipeline produces flow diagrams for domains/entities and the overall curriculum structure. flowchart LR A[Curriculum Generation] --> B[Structure Diagram] A --> C[Per-domain Flow] C --> D[Entity Flow] Examples (in-repo): - data/visualizations/curriculum_structure.mmd - data/visualizations/Coffee Roasting_flow.mmd - data/visualizations/Myrmecology_flow.mmd Section Breakdown Charts \u00b6 Bar charts summarizing section metrics. Artifacts: - data/visualizations/*_section_breakdown.png Metrics \u00b6 Aggregate curriculum metrics used for charts and diagnostics. Artifacts: - data/visualizations/curriculum_metrics.json - data/visualizations/curriculum_metrics.png How to Regenerate \u00b6 Run from learning/curriculum_creation/ : uv run python 3_Introduction_Visualizations.py","title":"Visualizations"},{"location":"visualizations/#visualizations","text":"Gallery and references for generated diagrams and charts.","title":"Visualizations"},{"location":"visualizations/#flow-diagrams-mermaid","text":"The pipeline produces flow diagrams for domains/entities and the overall curriculum structure. flowchart LR A[Curriculum Generation] --> B[Structure Diagram] A --> C[Per-domain Flow] C --> D[Entity Flow] Examples (in-repo): - data/visualizations/curriculum_structure.mmd - data/visualizations/Coffee Roasting_flow.mmd - data/visualizations/Myrmecology_flow.mmd","title":"Flow Diagrams (Mermaid)"},{"location":"visualizations/#section-breakdown-charts","text":"Bar charts summarizing section metrics. Artifacts: - data/visualizations/*_section_breakdown.png","title":"Section Breakdown Charts"},{"location":"visualizations/#metrics","text":"Aggregate curriculum metrics used for charts and diagnostics. Artifacts: - data/visualizations/curriculum_metrics.json - data/visualizations/curriculum_metrics.png","title":"Metrics"},{"location":"visualizations/#how-to-regenerate","text":"Run from learning/curriculum_creation/ : uv run python 3_Introduction_Visualizations.py","title":"How to Regenerate"},{"location":"other/","text":"Other Documents \u00b6 This section collects additional documents that don't fit into the main guides. Inferant Stream 015-1","title":"Overview"},{"location":"other/#other-documents","text":"This section collects additional documents that don't fit into the main guides. Inferant Stream 015-1","title":"Other Documents"},{"location":"other/inferant_stream_015-1/","text":"\u200bActive InferAnt Stream #015.1 start/here: Epistemic status: Working and useful though not complete or perfect. Date/Time: September 3, 5:00\u20136:00pm PT Agenda (concise) - 5:00 Welcome + context: start/here, ethos, goals - 5:05 Just ship it: minimal viable docs and scripts - 5:15 Central nexus tour: mkdocs.yml, run_docs.sh, nav and site structure - 5:25 Meta-documentation: Di\u00e1taxis mapping, tests-as-docs, prompts as specs - 5:35 Live build & deploy: local serve + GitHub Pages - 5:45 Q&A: issues, PRs, roadmapping - 5:55 Next steps and calls-to-action Title ideas (pick one live) - START/HERE: Just Ship It - start \u2192 here \u2192 now - The Central Nexus: Docs that Do - Meta-Documentation at the Core - README to Reality: Shipping the Docs - The Nexus is the Map - Docs as Product: Pragmatic Paths to Pages - One File to Route Them All (mkdocs.yml) - Press Build: From Local to Pages in Minutes - Just Do Docs (and Deploy) - START/HERE: The Connecting Tissue - Source of Truth: start/here as Central Node - Move Fast, Write Clearly: End-to-End Docs - From Notes to Navigation: A Site in One Sitting - Ship Small, Ship Often: Documentation Edition Links - Local: run ./run_docs.sh --serve \u2192 http://127.0.0.1:8000/ - Pages: https://ActiveInferenceInstitute.github.io/Start/","title":"Inferant Stream 015-1"}]}